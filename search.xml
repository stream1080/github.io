<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MySQL的执行计划(三)</title>
      <link href="/2021/11/11/mysql-de-zhi-xing-ji-hua-san/"/>
      <url>/2021/11/11/mysql-de-zhi-xing-ji-hua-san/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>select、poll和epoll的区别</title>
      <link href="/2021/11/07/select-poll-he-epoll-de-qu-bie/"/>
      <url>/2021/11/07/select-poll-he-epoll-de-qu-bie/</url>
      
        <content type="html"><![CDATA[<h2 id="进程所能打开的最大连接数"><a href="#进程所能打开的最大连接数" class="headerlink" title="进程所能打开的最大连接数"></a>进程所能打开的最大连接数</h2><h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p>单个进程所能打开的最大连接数有FD_ SETSIZE宏定义， 其大小是32个整数的大小(在32位的机器上，大小就是32<em>32，同理64位机器上FD_ SETSIZE为32</em>64) </p><p>tips：我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。</p><h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4><p>poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的</p><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接</p><h2 id="FD剧增后带来的IO效率问题"><a href="#FD剧增后带来的IO效率问题" class="headerlink" title="FD剧增后带来的IO效率问题"></a>FD剧增后带来的IO效率问题</h2><h4 id="select-1"><a href="#select-1" class="headerlink" title="select"></a>select</h4><p>因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历<br>速度慢的“线性下降性能问题”。</p><h4 id="poll-1"><a href="#poll-1" class="headerlink" title="poll"></a>poll</h4><p>由于poll与select的本质是一样的，所有poll有着和select一样的问题</p><h4 id="epoll-1"><a href="#epoll-1" class="headerlink" title="epoll"></a>epoll</h4><p>因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用calback,所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。</p><h2 id="消息传递方式"><a href="#消息传递方式" class="headerlink" title="消息传递方式"></a>消息传递方式</h2><h4 id="select-2"><a href="#select-2" class="headerlink" title="select"></a>select</h4><p>内核需要将消息传递到用户空间，都需要内核拷贝动作</p><h4 id="poll-2"><a href="#poll-2" class="headerlink" title="poll"></a>poll</h4><p>与select一样</p><h4 id="epoll-2"><a href="#epoll-2" class="headerlink" title="epoll"></a>epoll</h4><p>epoll通过内核和用户空间共享一块内存来 实现的</p><h2 id="select和epoll的区别。"><a href="#select和epoll的区别。" class="headerlink" title="select和epoll的区别。"></a>select和epoll的区别。</h2><p>select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。</p><p>select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。</p><p>内核需要传递消息到用户空间，需要内存拷贝</p><p>相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。</p><p>epoll能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。</p><p>效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。</p><h2 id="epoll的两种模式"><a href="#epoll的两种模式" class="headerlink" title="epoll的两种模式"></a>epoll的两种模式</h2><p>epoll对文件描述符的操作有两种模式：</p><ul><li>LT（level trigger）默认模式</li><li>ET（edge trigger）</li></ul><h3 id="LT模式"><a href="#LT模式" class="headerlink" title="LT模式"></a>LT模式</h3><p>当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。</p><p>LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket。<br>在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。</p><h3 id="ET模式"><a href="#ET模式" class="headerlink" title="ET模式"></a>ET模式</h3><p>当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</p><p>ET(edge-triggered)是高速工作方式，只支持no-block socket。</p><p>在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了</p><ul><li>比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误</li></ul><p>如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)。</p><ul><li>ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。</li><li>epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IO流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO多路复用</title>
      <link href="/2021/11/06/io-duo-lu-fu-yong/"/>
      <url>/2021/11/06/io-duo-lu-fu-yong/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄</p><ul><li>一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；</li><li>没有文件句柄就绪时会阻塞应用程序，交出cpu；</li><li>多路是指网络连接，复用指的是同一个线程。</li></ul><h2 id="三种实现方式"><a href="#三种实现方式" class="headerlink" title="三种实现方式"></a>三种实现方式</h2><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><ul><li>时间复杂度O(n)，它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），</li><li>只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。</li><li>所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> select <span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>readfds<span class="token punctuation">,</span> fd_set <span class="token operator">*</span>writefds<span class="token punctuation">,</span>             fd_set <span class="token operator">*</span>exceptfds<span class="token punctuation">,</span> struct timeval <span class="token operator">*</span>timeout<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><p>select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。<br>调用后select函数会阻塞，直到有：</p><ul><li>描述符就绪（有数据可读、可写、或者有except）</li><li>超时（timeout指定等待时间，如果立即返回设为null即可）</li><li>函数返回。</li></ul><p>当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。</p><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul><li>良好的跨平台支持，select目前几乎在所有的平台上支持。</li><li>单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024可以修改限制，但是这样也会造成效率的降低。</li></ul><h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>时间复杂度O(n)，poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， </p><ul><li>没有最大连接数的限制，原因是它是基于链表来存储的。</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> poll <span class="token punctuation">(</span>struct pollfd <span class="token operator">*</span>fds<span class="token punctuation">,</span> unsigned <span class="token keyword">int</span> nfds<span class="token punctuation">,</span> <span class="token keyword">int</span> timeout<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h4><p>poll使用一个 pollfd的指针实现。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">struct pollfd <span class="token punctuation">&#123;</span>    <span class="token keyword">int</span> fd<span class="token punctuation">;</span>            <span class="token comment">/* file descriptor */</span>    <span class="token keyword">short</span> events<span class="token punctuation">;</span>      <span class="token comment">/* requested events to watch */</span>    <span class="token keyword">short</span> revents<span class="token punctuation">;</span>     <span class="token comment">/* returned events witnessed */</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h4><p>pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。</p><ul><li>pollfd并没有最大数量限制（但是数量过大后性能也是会下降）</li><li>和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</li></ul><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>时间复杂度O(1)，epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。</p><ul><li>epoll实际上是事件驱动（每个事件关联上fd）的，此时对这些流的操作都是有意义的。</li></ul><h4 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h4><p>epoll操作过程需要三个接口，分别如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> <span class="token function">epoll_create</span><span class="token punctuation">(</span><span class="token keyword">int</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">epoll_ctl</span><span class="token punctuation">(</span><span class="token keyword">int</span> epfd<span class="token punctuation">,</span> <span class="token keyword">int</span> op<span class="token punctuation">,</span> <span class="token keyword">int</span> fd<span class="token punctuation">,</span> struct epoll_event <span class="token operator">*</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">epoll_wait</span><span class="token punctuation">(</span><span class="token keyword">int</span> epfd<span class="token punctuation">,</span> struct epoll_event <span class="token operator">*</span> events<span class="token punctuation">,</span>                <span class="token keyword">int</span> maxevents<span class="token punctuation">,</span> <span class="token keyword">int</span> timeout<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> <span class="token function">epoll_create</span><span class="token punctuation">(</span><span class="token keyword">int</span> size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值</li><li>参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。</li><li>当创建好epoll句柄后，它就会占用一个fd值，在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> <span class="token function">epoll_ctl</span><span class="token punctuation">(</span><span class="token keyword">int</span> epfd<span class="token punctuation">,</span> <span class="token keyword">int</span> op<span class="token punctuation">,</span> <span class="token keyword">int</span> fd<span class="token punctuation">,</span> struct epoll_event <span class="token operator">*</span>event<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>函数是对指定描述符fd执行op操作。</p><ul><li>epfd：是epoll_create()的返回值。</li><li>op：表示op操作，用三个宏来表示，分别添加、删除和修改对fd的监听事件。<ul><li>添加EPOLL_CTL_ADD，</li><li>删除EPOLL_CTL_DEL，</li><li>修改EPOLL_CTL_MOD。</li></ul></li><li>fd：是需要监听的fd（文件描述符）</li><li>epoll_event：是告诉内核需要监听什么事，</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> <span class="token function">epoll_wait</span><span class="token punctuation">(</span><span class="token keyword">int</span> epfd<span class="token punctuation">,</span> struct epoll_event <span class="token operator">*</span> events<span class="token punctuation">,</span>                <span class="token keyword">int</span> maxevents<span class="token punctuation">,</span> <span class="token keyword">int</span> timeout<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>等待epfd上的io事件，最多返回maxevents个事件。</p><ul><li>参数events用来从内核得到事件的集合</li><li>maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，</li><li>参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IO流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务之两阶段提交</title>
      <link href="/2021/11/03/fen-bu-shi-shi-wu-zhi-liang-jie-duan-ti-jiao/"/>
      <url>/2021/11/03/fen-bu-shi-shi-wu-zhi-liang-jie-duan-ti-jiao/</url>
      
        <content type="html"><![CDATA[<h2 id="两阶段提交协议"><a href="#两阶段提交协议" class="headerlink" title="两阶段提交协议"></a>两阶段提交协议</h2><ul><li>两阶段提交协议把分布式事务分为两个阶段，一个是准备阶段，另一个是提交阶段；</li><li>准备阶段和提交阶段都是由事务管理器发起的；</li><li>我们可以将事务管理器称为协调者，将资源管理器称为参与者。</li></ul><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h4 id="准备阶段："><a href="#准备阶段：" class="headerlink" title="准备阶段："></a>准备阶段：</h4><p>协调者向参与者发起指令，参与者评估自己的状态，如果参与者评估指令可以完成，则会写redo或者undo日志（Write-Ahead Log的一种），然后锁定资源，执行操作，但是并不提交。<br><img src="https://img-blog.csdnimg.cn/7f5ba60ae0344ac6af22a614986d0f71.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h4 id="提交阶段："><a href="#提交阶段：" class="headerlink" title="提交阶段："></a>提交阶段：</h4><ul><li>如果每个参与者明确返回准备成功，也就是预留资源和执行操作成功，则协调者向参与者发起提交指令，参与者提交资源变更的事务，释放锁定的资源；</li><li>如果任何一个参与者明确返回准备失败，也就是预留资源或者执行操作失败，则协调者向参与者发起中止指令，参与者取消已经变更的事务，执行undo日志，释放锁定的资源。<img src="https://img-blog.csdnimg.cn/c4705696bb2f461aa55698bbd4fc8b19.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul><h2 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h2><p>两阶段提交协议在准备阶段锁定资源，这是一个非常损耗资源的操作，能保证强一致性，但是实现起来复杂、成本较高、不够灵活，更重要的是它有一些致命的问题</p><h4 id="阻塞："><a href="#阻塞：" class="headerlink" title="阻塞："></a>阻塞：</h4><p>从上面的描述来看，对于任何一次指令都必须收到明确的响应，才会继续进行下一步，否则处于阻塞状态，占用的资源被一直锁定，不会被释放。</p><h4 id="单点故障："><a href="#单点故障：" class="headerlink" title="单点故障："></a>单点故障：</h4><p>如果协调者宕机，参与者没有协调者指挥，则会一直阻塞，尽管可以通过选举新的协调者替代原有协调者，但是如果协调者在发送一个提交指令后宕机，而提交指令仅仅被一个参与者接收，并且参与者接收后也宕机，则新上任的协调者无法处理这种情况。</p><h4 id="脑裂："><a href="#脑裂：" class="headerlink" title="脑裂："></a>脑裂：</h4><p>协调者发送提交指令，有的参与者接收到并执行了事务，有的参与者没有接收到事务就没有执行事务，多个参与者之间是不一致的。</p><h4 id="数据状态不确定"><a href="#数据状态不确定" class="headerlink" title="数据状态不确定"></a>数据状态不确定</h4><p>协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>上面的问题发生的概论比较小，但都需要人工干预处理，没有自动化的解决方案，因此两阶段提交协议在正常情况下能保证系统的强一致性，但是在出现异常的情况下，当前处理的操作处于错误状态，需要人工干预解决，因此可用性不够好。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式事务 </tag>
            
            <tag> 数据一致性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务之三阶段提交</title>
      <link href="/2021/11/02/fen-bu-shi-shi-wu-zhi-san-jie-duan-ti-jiao/"/>
      <url>/2021/11/02/fen-bu-shi-shi-wu-zhi-san-jie-duan-ti-jiao/</url>
      
        <content type="html"><![CDATA[<p>三阶段提交协议是两阶段提交协议的改进版本，它通过超时机制解决了阻塞的问题，并且把两个阶段增加为三个阶段。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h4 id="询问阶段"><a href="#询问阶段" class="headerlink" title="询问阶段"></a>询问阶段</h4><p>协调者询问参与者是否可以完成指令，协调者只需要回答是或不是，而不需要做真正的操作，这个阶段超时会导致中止。<br><img src="https://img-blog.csdnimg.cn/94897bae453343b6ac1c56b83a55d314.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h4 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h4><ul><li>如果在询问阶段所有参与者都返回可以执行操作，则协调者向参与者发送预执行请求，然后参与者写redo和undo日志，执行操作但是不提交操作；</li><li>如果在询问阶段任意参与者返回不能执行操作的结果，则协调者向参与者发送中止请求，这里的逻辑与两阶段提交协议的准备阶段是相似的。<br><img src="https://img-blog.csdnimg.cn/b04e26303c904cb9b78826d5b597b186.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul><h4 id="提交阶段"><a href="#提交阶段" class="headerlink" title="提交阶段"></a>提交阶段</h4><ul><li><p>如果每个参与者在准备阶段返回准备成功，也就是说预留资源和执行操作成功，则协调者向参与者发起提交指令，参与者提交资源变更的事务，释放锁定的资源；</p></li><li><p>如果任何参与者返回准备失败，也就是说预留资源或者执行操作失败，则协调者向参与者发起中止指令，参与者取消已经变更的事务，执行 undo 日志，释放锁定的资源，这里的逻辑与两阶段提交协议的提交阶段一致。<br><img src="https://img-blog.csdnimg.cn/1cdb4a63102844b5aa07b1aec7ca680d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="三阶段提交协议的成功场景示意图如下图所示："></p><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2></li><li><p>增加了一个询问阶段，询问阶段可以确保尽可能早地发现无法执行操作而需要中止的行为，但是它并不能发现所有这种行为，只会减少这种情况的发生。</p></li><li><p>在准备阶段以后，协调者和参与者执行的任务中都增加了超时，一旦超时，则协调者和参与者都会继续提交事务，默认为成功，这也是根据概率统计超时后默认为成功的正确性最大。</p></li><li><p>三阶段提交协议与两阶段提交协议相比，具有如上优点，但是一旦发生超时，系统仍然会发生不一致，只不过这种情况很少见，好处是至少不会阻塞和永远锁定资源。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式事务 </tag>
            
            <tag> 数据一致性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ 如何保证消息不会被重复消费</title>
      <link href="/2021/10/30/rabbitmq-ru-he-bao-zheng-xiao-xi-bu-hui-bei-chong-fu-xiao-fei/"/>
      <url>/2021/10/30/rabbitmq-ru-he-bao-zheng-xiao-xi-bu-hui-bei-chong-fu-xiao-fei/</url>
      
        <content type="html"><![CDATA[<p>所有的消息队列都要保证同一条消息不会被重复消费</p><ul><li>举个例子：假设有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据就错了</li><li>所以消费到第二次的时候，自己判断一下已经消费过了，直接扔了，就保留了一条数据</li></ul><p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性幂等性。</p><ul><li>一个请求重复多次，需要确保对应的数据是不会改变的，不能出错。<h2 id="为什么会重复消费"><a href="#为什么会重复消费" class="headerlink" title="为什么会重复消费"></a>为什么会重复消费</h2>（1）生产者重复发送消息：生产者在往消息队列发送消息时，发生了网络抖动，生产者没有收到确认信号，但是实际上消息队列已经收到了消息，超过一定时间后生产者会重新发送消息，这时一条消息被发送了两次；<br>（2）消费者重复接受消息：消费者成功消费消息后，发生了网络抖动，消息队列没有收到确认信号，超过一段时间后会重新给消费者投递相同的消息，同一条消息即存在被消费两次的可能。</li></ul><h2 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h2><p>通用解决方案是在消息实体中添加全局唯一的id，例如 msg_id（消息ID），在代码中保证消息的幂等性，</p><ul><li>消费者在收到消息之后，根据 msg_id 从缓存或者数据库中查询是否存在已有消息；</li><li>如果不存在已有消息，那么消费之后，将 msg_id 对应的消息实体或者序列化对象写入缓存或者数据库；</li><li>如果存在已有消息，说明这条消息已被消费过，丢弃消息并且打一条告警日志。</li></ul><p>并且可以根据重复消费的容忍程度以及性能要求选择使用缓存还是使用数据库，</p><ul><li>如果对判断的速度要求高，可以使用 Redis 作为缓存；</li><li>如果对判断的稳定性和鲁棒性要求高，使用数据库存储消息实体，同时将 msg_id 作为数据库表的唯一键，插入重复记录一定会抛出异常，避免数据库因为并发问题产生脏数据，保证了消息消费的不可重复性。</li></ul><h2 id="结合业务分析"><a href="#结合业务分析" class="headerlink" title="结合业务分析"></a>结合业务分析</h2><ul><li>如果是对数据库进行写库，先根据主键查一下，如果这数据都有了，就不写入</li><li>如果是写redis，那没问题了，反正每次都是set，天然幂等性。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
            <tag> 重复消费 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ如何保证消息顺序消费</title>
      <link href="/2021/10/29/rabbitmq-ru-he-bao-zheng-xiao-xi-shun-xu-xiao-fei/"/>
      <url>/2021/10/29/rabbitmq-ru-he-bao-zheng-xiao-xi-shun-xu-xiao-fei/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么要顺序消费"><a href="#为什么要顺序消费" class="headerlink" title="为什么要顺序消费"></a>为什么要顺序消费</h2><p>保证消息的顺序消费是生产业务场景下经常面临的挑战，例如电商的下单逻辑，在用户下单之后，会发送创建订单和扣减库存的消息，我们需要保证扣减库存在创建订单之后执行。</p><ul><li>处理业务逻辑后，向MQ发送一条消息，再由消费者从 MQ 中获取 消息落盘到MySQL 中。</li><li>在这个过程中，可能会有增删改的操作，比如执行顺序是增加、修改、删除。</li><li>消费者可能换了顺序给执行成删除、修改、增加，所以我们要保证消息的顺序消费</li></ul><h2 id="为什么会不按顺序消费"><a href="#为什么会不按顺序消费" class="headerlink" title="为什么会不按顺序消费"></a>为什么会不按顺序消费</h2><p>对于 RabbitMQ 来说，导致上面顺序错乱的原因通常是消费者是集群部署，不同的消费者消费到了同一订单的不同的消息。</p><ul><li>如消费者1执行了增加，消费者2执行了修改，消费者C执行了删除</li><li>但是消费者C执行比消费者B快，消费者B又比消费者A快，就会导致消费消息的时候顺序错乱</li><li>本该顺序是增加、修改、删除，变成了删除、修改、增加.<br><img src="https://img-blog.csdnimg.cn/77a568c090d24eb68f041cd17126220b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul><h2 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h2><p>RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。</p><ul><li>我们可以给 RabbitMQ 创建多个 queue，每个消费者固定消费一个 queue 的消息，</li><li>生产者发送消息的时候，同一个类型的消息发送到同一个 queue 中</li><li>由于同一个 queue 的消息是一定会保证有序的，那么同一个订单号的消息就只会被一个消费者顺序消费，从而保证了消息的顺序性。<br><img src="https://img-blog.csdnimg.cn/d8c2d643644646f9be78cf4884a828ff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
            <tag> 顺序消费 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP的粘包和拆包</title>
      <link href="/2021/10/13/tcp-de-nian-bao-he-chai-bao/"/>
      <url>/2021/10/13/tcp-de-nian-bao-he-chai-bao/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是粘包和拆包"><a href="#什么是粘包和拆包" class="headerlink" title="什么是粘包和拆包"></a>什么是粘包和拆包</h2><p>一个完整的业务数据包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这个就是TCP的拆包和粘包问题。</p><h4 id="第一种情况-正常"><a href="#第一种情况-正常" class="headerlink" title="第一种情况(正常)"></a>第一种情况(正常)</h4><p>接收端正常收到两个数据包，即没有发生拆包和粘包的现象；</p><p><img src="https://img-blog.csdnimg.cn/0dd185d80ed7419c99f241e13d97b33c.png" alt="在这里插入图片描述"></p><h4 id="第二种情况"><a href="#第二种情况" class="headerlink" title="第二种情况"></a>第二种情况</h4><p>接收端只收到一个数据包，由于TCP是不会出现丢包的，所以这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。</p><p>这种情况由于接收端不知道这两个数据包的界限，所以对于接收端来说很难处理。<br><img src="https://img-blog.csdnimg.cn/5b0e17395ab0423a8b2c275fcf8de9eb.png" alt="在这里插入图片描述"></p><h4 id="第三种情况"><a href="#第三种情况" class="headerlink" title="第三种情况"></a>第三种情况</h4><p>接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。<br><img src="https://img-blog.csdnimg.cn/2ebf028e7f7a404490314f5d6f41cd86.png" alt="在这里插入图片描述"><br>这两种情况如果不加特殊处理，对于接收端同样是不好处理的<br><img src="https://img-blog.csdnimg.cn/0b1efe60580848bca400bf9e802a7fef.png" alt="在这里插入图片描述"></p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><ol><li><p>应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。</p></li><li><p>应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。</p></li><li><p>进行MSS（最大报文长度）大小的TCP分段，当TCP报文长度-TCP头部长度&gt;MSS的时候将发生拆包。</p></li><li><p>接收方法不及时读取套接字缓冲区数据，这将发生粘包。</p></li></ol><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><ol><li><p>发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。</p></li><li><p>发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。</p></li><li><p>可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP/IP </tag>
            
            <tag> 粘包拆包 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于RedLock的分布式锁</title>
      <link href="/2021/10/12/ji-yu-redlock-de-fen-bu-shi-suo/"/>
      <url>/2021/10/12/ji-yu-redlock-de-fen-bu-shi-suo/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在单个主节点的架构上实现分布式锁，是无法保证高可用的，在生产环境上，我们的Redis都是以集群部署的；</p><p>那么如果Redis实现分布式锁的是一个主从集群，可能会发生什么情况呢？<br><img src="https://img-blog.csdnimg.cn/df7cdf3ffafb4a0aab070ad0ab176867.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ul><li>如果进程A在主节点上加锁成功，然后这个主节点宕机了，则从节点将会晋升为主节点。</li><li>若此时进程B在新的主节点上加锁成功，之后原主节点重启，成为了从节点，系统中将同时出现两把锁，这是违背锁的唯一性原则的。</li></ul><h2 id="RedLock实现"><a href="#RedLock实现" class="headerlink" title="RedLock实现"></a>RedLock实现</h2><p>如果要保证分布式锁的高可用，则需要采用多个节点的实现方案。</p><p>Redis的官方给出的建议是采用RedLock算法的实现方案。该算法基于多个Redis节点</p><h4 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h4><ul><li>集群中的节点相互独立，不存在主从复制或者集群协调机制；</li><li>加锁：以相同的KEY向N个实例加锁，只要超过一半节点成功，则认定加锁成功；</li><li>解锁：向所有的实例发送DEL命令，进行解锁；<br><img src="https://img-blog.csdnimg.cn/6f1b548a5a5549dd8bc90cfff64a715b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4></li></ul><ol><li><p>获取当前时间戳</p></li><li><p>client尝试按照顺序使用相同的key,value获取所有redis服务的锁，在获取锁的过程中的获取时间比锁过期时间短很多，这是为了不要过长时间等待已经关闭的redis服务。并且试着获取下一个redis实例。比如：TTL为5s,设置获取锁最多用1s，所以如果一秒内无法获取锁，就放弃获取这个锁，从而尝试获取下个锁</p></li><li><p>client通过获取所有能获取的锁后的时间减去第一步的时间，这个时间差要小于TTL时间并且至少有超过一半的redis实例成功获取锁，才算真正的获取锁成功</p></li><li><p>如果成功获取锁，则锁的真正有效时间是 TTL减去第三步的时间差 的时间；比如：TTL 是5s,获取所有锁用了2s,则真正锁有效时间为3s(其实应该再减去时钟漂移);</p></li><li><p>如果客户端由于某些原因获取锁失败，便会开始解锁所有redis实例；因为可能已经获取了小于一半的redis实例的锁，必须释放，否则影响其他client获取锁</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis实现分布式锁</title>
      <link href="/2021/10/10/redis-shi-xian-fen-bu-shi-suo/"/>
      <url>/2021/10/10/redis-shi-xian-fen-bu-shi-suo/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><p>分布式锁其实可以理解为:控制分布式系统有序的去对共享资源进行操作,通过互斥来保持一致性</p><h2 id="为什么要分布式锁"><a href="#为什么要分布式锁" class="headerlink" title="为什么要分布式锁"></a>为什么要分布式锁</h2><p>当多个线程需要并发修改一个数据时，为了避免竞争，在单机的情况下，加synchronized或者Lock即可实现互斥</p><p>但在分布式的环境下，当多个server并发修改同一个资源时，为了避免竞争就需要使用分布式锁。</p><p>那为什么不能使用Java自带的锁（synchronized或者Lock）呢？</p><ul><li>因为Java中的锁是面向多线程设计的，它只局限于当前的实例。</li><li>而多个server实际上是多进程，是不同的实例，所以Java自带的锁机制在这个场景下是无效的。</li></ul><h2 id="如何实现分布式锁"><a href="#如何实现分布式锁" class="headerlink" title="如何实现分布式锁"></a>如何实现分布式锁</h2><p>采用Redis实现分布式锁，就是在Redis里存一份代表锁的数据，通常用随机字符串即可。</p><h3 id="加锁："><a href="#加锁：" class="headerlink" title="加锁："></a>加锁：</h3><h4 id="第一种方式"><a href="#第一种方式" class="headerlink" title="第一种方式"></a>第一种方式</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">setnx key value<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这种方式的缺点是容易产生死锁，因为客户端有可能忘记解锁，或者解锁失败。</p><h4 id="第二种方式"><a href="#第二种方式" class="headerlink" title="第二种方式"></a>第二种方式</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">setnx key valueexpire key seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>给锁增加了过期时间，避免出现死锁。但这两个命令不是原子的，第二步可能会失败，依然无法避免死锁问题。</p><h4 id="第三种方式"><a href="#第三种方式" class="headerlink" title="第三种方式"></a>第三种方式</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">set key value nx ex seconds <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过“set…nx…”命令，将加锁、过期命令编排到一起，它们是原子操作了，可以避免死锁。</p><h3 id="解锁："><a href="#解锁：" class="headerlink" title="解锁："></a>解锁：</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">del key<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解锁就是删除代表锁的那份数据，直接删除redis上面的数据。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>上述方法看起来没有问题，但实际是有隐患的<br><img src="https://img-blog.csdnimg.cn/4678bef1efc04094b02729431c2069d8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ol><li>进程A在任务没有执行完毕时，锁已经到期被释放了。</li><li>等进程A的任务执行结束后，A会尝试释放锁，但是，它的锁已经过期不存在了，它此时释放的可能是其他线程的锁，比如B进程；</li><li>红框时间内，两个进程同时操作数据，极有可能出现线程安全的问题；</li></ol><h3 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h3><p>在加锁时就要给锁设置一个标识，加锁进程要记住这个标识。</p><ul><li>当进程解锁的时候，进行判断，是自己持有的锁才能释放</li><li>否则无法释放。可以为key设置一个随机字符串，来充当进程的标识。</li></ul><p>但是解锁的时候，判断、释放，这两步需要保证原子性，否则第二步失败的话，就会出现死锁，但判断和删除命令不是原子的。</p><p>在Redis中可以使用Lua脚本，通过Lua脚本将两个命令编排在一起，而整个Lua脚本的执行是原子的。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"># 加锁set key random<span class="token operator">-</span>value nx ex seconds # 解锁<span class="token keyword">if</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">"get"</span><span class="token punctuation">,</span>KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> ARGV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> then    <span class="token keyword">return</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">"del"</span><span class="token punctuation">,</span>KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">else</span>    <span class="token keyword">return</span> <span class="token number">0</span>end<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis-有序集合的数据结构</title>
      <link href="/2021/10/06/redis-you-xu-ji-he-de-shu-ju-jie-gou/"/>
      <url>/2021/10/06/redis-you-xu-ji-he-de-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<h2 id="集合概念"><a href="#集合概念" class="headerlink" title="集合概念"></a>集合概念</h2><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>Set类似于Java中的HashSet 。Redis中的set类型是一种无序集合，集合中的元<br>素没有先后顺序，并且不可重复。</p><p>当需要存储一个列表数据，又不不能出现重复数据时，Set 是一个很好的选择，并且set提供了判断某个成员是否在一个Set集合内的接口，List是没有这种接口的</p><p>可以基于set轻易实现交集、并集、差集的操作。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</p><h3 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h3><p>和Set相比，sorted set增加了一个权重参数score, 使得集合中的元素能够按score<br>进行有序排列，还可以通过score的范围来获取元素的列表。有点像是Java中HashMap和TreeSet的结合体。</p><p>其有两种实现方式，分别是ziplist和skiplist</p><h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><p>当有序集合保存的元素数量小于128个或者有序集合保存的所有元素的长度小于64字节时，Zset选用ziplist实现，其他情况选用skiplist实现；</p><h3 id="ziplist-压缩列表"><a href="#ziplist-压缩列表" class="headerlink" title="ziplist - 压缩列表"></a>ziplist - 压缩列表</h3><p>ziplist，顾名思义压缩列表，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的value，第二个元素保存元素的score；<br><img src="https://img-blog.csdnimg.cn/c4876263c60945998016ba6c5f3e7889.png" alt="在这里插入图片描述"></p><h3 id="skiplist-跳表"><a href="#skiplist-跳表" class="headerlink" title="skiplist - 跳表"></a>skiplist - 跳表</h3><p>跳表(skip List)是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为logn。</p><p>简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供logn的时间复杂度</p><p>普通链表<br><img src="https://img-blog.csdnimg.cn/92511fe8120b48a1af0a80a8a2c0f349.png" alt="在这里插入图片描述"></p><p>在普通链表中，如果我们要查找某个元素，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找完所有的节点（没找到）。</p><ul><li>这样的话，时间复杂度为O(n)；</li><li>当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置</li></ul><p>跳表</p><p><img src="https://img-blog.csdnimg.cn/01ce37da07c940b6b717e644c524d5f4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如上图，比如节点是1 - 2 - 3 - 4 - 5，增加节点1 - 3 - 5</p><p>这样形成一个新的链表，但它包含的节点个数只有原来的一半1，3，5</p><ul><li>当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。</li><li>比如查找3，之间可用从1指向3，即可跳过2，当数据量大的时候，只需要查询原有数据量的一半</li></ul><p>利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。<br><img src="https://img-blog.csdnimg.cn/9e80530dd5324377ae5aa097a26751a4.png" alt="在这里插入图片描述"><br>依次类推，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。</p><p>skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。</p><h3 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h3><p>这种数据结构可用加快查询速度，但是在插入删除数据是就会出现问题</p><ul><li>新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。</li><li>如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。</li><li>删除数据也有同样的问题。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 有序集合 </tag>
            
            <tag> 跳表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL的执行计划(二)</title>
      <link href="/2021/10/06/mysql-de-zhi-xing-ji-hua-er/"/>
      <url>/2021/10/06/mysql-de-zhi-xing-ji-hua-er/</url>
      
        <content type="html"><![CDATA[<p>书接上回：<a href="https://blog.csdn.net/upstream480/article/details/120615005">MySQL执行计划(一)</a></p><h2 id="执行计划中的列"><a href="#执行计划中的列" class="headerlink" title="执行计划中的列"></a>执行计划中的列</h2><h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><p>type列指代访问类型，是MySQL决定如何查找表中的行。</p><p>是SQL查询优化中一个很重要的指标，拥有很多值，依次从最差到最优：</p><h4 id="ALL"><a href="#ALL" class="headerlink" title="ALL"></a>ALL</h4><p>全表扫描，性能最差，在写SQL时尽量避免此种情况的出现，也就是避免是</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/e83044a80d254d0fb5fc9357bb7e521c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h4 id="index"><a href="#index" class="headerlink" title="index"></a>index</h4><p>全索引查询，和全表查询的ALL类似，但是扫描表时按索引次序进行（遍历索引树），而不是按行扫描</p><p>index与ALL虽然都是读全表，但index是从索引中读取，而ALL是从硬盘读取。<br>显然，index性能上明显优于ALL，所有，合理的添加索引将有助于提升性能。</p><p>举例如下：<br><img src="https://img-blog.csdnimg.cn/2fabd07cdb3d4966b999143de1a18214.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h4 id="range"><a href="#range" class="headerlink" title="range"></a>range</h4><p>只查询给定范围的行，使用一个索引来选择行。</p><ul><li>key列显示使用了那个索引；</li><li>一般就是在where语句中出现了bettween、&lt;、&gt;、in等的查询；</li><li>这种索引列上的范围扫描比全索引扫描index要好。<img src="https://img-blog.csdnimg.cn/623618fb584d447e96dd743f8d47c7ee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><h4 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h4>非唯一性索引扫描，返回匹配某个单独值的所有行。本质是也是一种索引访问，它返回所有匹配某个单独值的行，然而它可能会找到多个符合条件的行，所以它属于查找和扫描的混合体。</li></ul><p>此类型只有当使用非唯一索引或者唯一索引的非唯一性前缀时，才会发生。<br><img src="https://img-blog.csdnimg.cn/0d76d82b62b14e6dbdb453d2a7e561c0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h4 id="eq-ref"><a href="#eq-ref" class="headerlink" title="eq_ref"></a>eq_ref</h4><ul><li>唯一索引扫描</li><li>主要用于主键或唯一索引扫描。</li></ul><h4 id="const"><a href="#const" class="headerlink" title="const"></a>const</h4><ul><li>通过索引一次就能找到，const用于比较primary key 或者unique索引。</li><li>因为只需匹配一行数据，所有很快。</li><li>将主键置于where列表中，mysql就能将该查询转换为一个const。<br><img src="https://img-blog.csdnimg.cn/accbeada941a4b16ada04d80985d3232.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul><h4 id="system"><a href="#system" class="headerlink" title="system"></a>system</h4><ul><li>表只有一行记录，这是const类型的特例，比较少见。</li></ul><p>下一篇<br><a href="https://blog.csdn.net/upstream480/article/details/120616953">MySQL执行计划(三)</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 执行计划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL的执行计划(一)</title>
      <link href="/2021/10/05/mysql-de-zhi-xing-ji-hua-yi/"/>
      <url>/2021/10/05/mysql-de-zhi-xing-ji-hua-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是执行计划"><a href="#什么是执行计划" class="headerlink" title="什么是执行计划"></a>什么是执行计划</h2><p>执行计划，就是一条SQL语句，在数据库中实际执行的时候，一步步的分别都做了什么事情</p><p>EXPLAIN命令是查看查询优化器是如何决定执行查询的主要方法，从它的查询结果中我们可以知道：</p><ul><li>一个SQL语句每一步是如何执行的；</li><li>都做了哪些事，分为哪几步；</li><li>有没有用到索引；</li><li>哪些字段用到了什么样的索引，是否有一些可优化的地方等。</li></ul><p>查看执行计划，只需在查询中的SELECT关键字之前增加EXPLAIN即可</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">语法：<span class="token keyword">EXPLAIN</span> <span class="token operator">+</span> <span class="token keyword">SELECT</span>查询语句示例：<span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">user</span><span class="token punctuation">`</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>使用EXPLAIN时，会返回执行计划中每一步的信息，它会返回一行或多行信息，显示出执行计划中的每一部分和执行的次序。</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">user</span><span class="token punctuation">`</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/65163a07c98048638d4dfab62c0045a8.png" alt="在这里插入图片描述"></p><h2 id="执行计划中的列"><a href="#执行计划中的列" class="headerlink" title="执行计划中的列"></a>执行计划中的列</h2><p><img src="https://img-blog.csdnimg.cn/bb0128492f804b059e162e8af194fd0a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="Id"><a href="#Id" class="headerlink" title="Id"></a>Id</h3><p>id是一个编号，用于标识SELECT查询的序列号，表示执行SQL查询过程中SELECT子句或操作表的顺序。</p><ul><li>如果在SQL语句中没有子查询或关联查询，那么id列为1</li><li>否则，内层的SELECT语句一般会顺序编号；</li></ul><p>Id列可能会存在三种情况，以下一一列举：</p><h4 id="Id相同"><a href="#Id相同" class="headerlink" title="Id相同"></a>Id相同</h4><p>只有普通的查询，没有子查询，则Id相同为1</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">user</span><span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span><span class="token keyword">comment</span><span class="token punctuation">`</span> <span class="token keyword">WHERE</span> <span class="token punctuation">`</span><span class="token keyword">comment</span><span class="token punctuation">`</span><span class="token punctuation">.</span>user_id <span class="token operator">=</span> <span class="token punctuation">`</span><span class="token keyword">user</span><span class="token punctuation">`</span><span class="token punctuation">.</span>id<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/057a89f6b571498fbefb5f821a4145a2.png" alt="在这里插入图片描述"></p><h4 id="Id不同"><a href="#Id不同" class="headerlink" title="Id不同"></a>Id不同</h4><p>存在子查询，id的序号会递增，id值越大优先级越高，越先被执行。</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">user</span><span class="token punctuation">`</span> <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> user_id <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">comment</span><span class="token punctuation">`</span> <span class="token keyword">WHERE</span> entity_type <span class="token operator">=</span> <span class="token number">2</span> <span class="token keyword">LIMIT</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/310ff579697e43a497a2a7970fc28bb4.png" alt="在这里插入图片描述"></p><h4 id="Id相同和不同"><a href="#Id相同和不同" class="headerlink" title="Id相同和不同"></a>Id相同和不同</h4><p>id如果相同，认为是一组，从从上往下执行。<br>在所有组中，id值越大，优先级越高，越先执行。</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">user</span><span class="token punctuation">`</span> <span class="token keyword">WHERE</span> id <span class="token operator">IN</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> user_id <span class="token keyword">FROM</span> <span class="token punctuation">`</span><span class="token keyword">comment</span><span class="token punctuation">`</span> <span class="token keyword">WHERE</span> entity_type <span class="token operator">=</span> <span class="token number">2</span> <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://img-blog.csdnimg.cn/03a08fc0cd824c5181da896aabfb1815.png" alt="在这里插入图片描述"></p><h3 id="select-type列"><a href="#select-type列" class="headerlink" title="select_type列"></a>select_type列</h3><p>select_type列表示对应行的查询类型，是简单查询还是复杂查询</p><ul><li>主要用于区分普通查询、联合查询、子查询等复杂的查询。<br><img src="https://img-blog.csdnimg.cn/522f97c08a8d423a881a4973d547b41d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><h3 id="table"><a href="#table" class="headerlink" title="table"></a>table</h3>table列表示对应行正在执行的哪张表，指代对应表名</li><li>如果SQL中定义了别名，则会显示该表的别名</li></ul><h3 id="partitions"><a href="#partitions" class="headerlink" title="partitions"></a>partitions</h3><ul><li>查询涉及到的分区。</li></ul><p>下一篇</p><p><a href="https://blog.csdn.net/upstream480/article/details/120615700">MySQL执行计划(二)</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 执行计划 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
